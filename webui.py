import gradio as gr
from gradio_client import Client, file
import os
import shutil
import subprocess

# GPT-SoVITS API åœ°å€
GPT_SOVITS_API_URL = "http://localhost:9872/"

# åˆå§‹åŒ– API å®¢æˆ·ç«¯
client = Client(GPT_SOVITS_API_URL)

# è·å– GPT-SoVITS æœåŠ¡å™¨ä¸Šå¯ç”¨çš„ SoVITS è¯­éŸ³æ¨¡å‹å’Œ GPT è¯­éŸ³æ¨¡å‹
def get_available_models():
    result = client.predict(api_name="/change_choices")
    if not isinstance(result, tuple) or len(result) < 2:
        raise ValueError(f"API è¿”å›æ ¼å¼ä¸æ­£ç¡®: {result}")
    
    # è§£æ SoVITS è¯­éŸ³æ¨¡å‹
    sovits_models = [model[0] for model in result[0]["choices"]]
    
    # è§£æ GPT è¯­éŸ³æ¨¡å‹
    gpt_models = [model[0] for model in result[1]["choices"]]

    print("ğŸ”¹ å¯ç”¨çš„ SoVITS è¯­éŸ³æ¨¡å‹:", sovits_models)
    print("ğŸ”¹ å¯ç”¨çš„ GPT è¯­éŸ³æ¨¡å‹:", gpt_models)

    return sovits_models, gpt_models

# åˆ‡æ¢ SoVITS å’Œ GPT è¯­éŸ³æ¨¡å‹
def change_models(sovits_model, gpt_model):
    client.predict(
        sovits_path=sovits_model,
        prompt_language="ä¸­æ–‡",
        text_language="ä¸­æ–‡",
        api_name="/change_sovits_weights"
    )
    print(f"å·²åˆ‡æ¢ SoVITS è¯­éŸ³æ¨¡å‹: {sovits_model}")
    
    client.predict(
        gpt_path=gpt_model,
        api_name="/change_gpt_weights"
    )
    print(f"å·²åˆ‡æ¢ GPT è¯­éŸ³æ¨¡å‹: {gpt_model}")

# é€šè¿‡ GPT-SoVITS API ç”Ÿæˆè¯­éŸ³
def generate_speech(ref_audio_path, text, sovits_model, gpt_model, prompt_text, prompt_language, how_to_cut, top_k, top_p, temperature, ref_free, speed, if_freeze, sample_steps):
    # åˆ‡æ¢æ¨¡å‹
    change_models(sovits_model, gpt_model)

    # ç”Ÿæˆè¯­éŸ³
    print("æ­£åœ¨å‘ GPT-SoVITS å‘é€ TTS è¯·æ±‚...\n\n")
    
    result = client.predict(
        ref_wav_path=file(ref_audio_path),
        prompt_text=prompt_text,
        prompt_language=prompt_language,
        text=text,
        text_language="ä¸­æ–‡",
        how_to_cut=how_to_cut,
        top_k=top_k,
        top_p=top_p,
        temperature=temperature,
        ref_free=ref_free,
        speed=speed,
        if_freeze=if_freeze,
        inp_refs=None,
        sample_steps=sample_steps,
        api_name="/get_tts_wav"
    )

    # æ‰“å°è¿”å›çš„è·¯å¾„å¹¶æ£€æŸ¥æ–‡ä»¶
    print(f"API è¿”å›çš„éŸ³é¢‘è·¯å¾„: {result}")

    if not os.path.exists(result):
        raise ValueError(f"API ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {result}")

    # ç›®æ ‡è·¯å¾„
    output_audio_path = os.path.join("output", "generated_audio.wav")
    shutil.copy(result, output_audio_path)
    print(f"è¯­éŸ³åˆæˆå®Œæˆ: {output_audio_path}")

    # ç”Ÿæˆè§†é¢‘çš„ç›®æ ‡è·¯å¾„
    output_video_path = os.path.join("E:/Project/Digital_Human/Wav2Lip/results", "result_voice.mp4")

    # Wav2Lip æ‰€éœ€ç¯å¢ƒè·¯å¾„
    wav2lip_env_path = "E:/Project/Digital_Human/Wav2Lip/env"
    wav2lip_script_path = "E:/Project/Digital_Human/Wav2Lip/inference.py"
    wav2lip_checkpoint_path = "E:/Project/Digital_Human/Wav2Lip/models/wav2lip_gan.pth"
    input_video_path = "E:\Project\Digital_Human\input\input.mp4"

    # ç»„è£…å®Œæ•´çš„ shell å‘½ä»¤
    wav2lip_command = f'''
    conda run -p "{wav2lip_env_path}" python "{wav2lip_script_path}" --checkpoint_path "{wav2lip_checkpoint_path}" --face "{input_video_path}" --audio "{output_audio_path}"
    '''

    # è°ƒç”¨ Wav2Lip è¿›è¡Œè§†é¢‘ç”Ÿæˆ
    try:
        process = subprocess.run(wav2lip_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        # æ‰“å°è¾“å‡ºæ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
        print(f"ğŸ”¹ Wav2Lip è¾“å‡º: {process.stdout}")
        print(f"ğŸ”¹ Wav2Lip é”™è¯¯: {process.stderr}")

        if process.returncode == 0:
            print(f"Wav2Lip è§†é¢‘ç”ŸæˆæˆåŠŸ: {output_video_path}")
        else:
            print(f"Wav2Lip å¤±è´¥ï¼Œé”™è¯¯ä»£ç : {process.returncode}")

    except subprocess.CalledProcessError as e:
        print(f"è°ƒç”¨ Wav2Lip ç”Ÿæˆè§†é¢‘å¤±è´¥: {e}")
        
    return output_audio_path, output_video_path

# è·å–å¯ç”¨æ¨¡å‹å¹¶åˆå§‹åŒ–
sovits_models, gpt_models = get_available_models()

# Gradio ç•Œé¢
def gradio_interface(ref_audio, text, sovits_model, gpt_model, prompt_text, prompt_language, how_to_cut, top_k, top_p, temperature, ref_free, speed, if_freeze, sample_steps):
    return generate_speech(ref_audio, text, sovits_model, gpt_model, prompt_text, prompt_language, how_to_cut, top_k, top_p, temperature, ref_free, speed, if_freeze, sample_steps)

# æ„å»º Gradio ç•Œé¢
with gr.Blocks() as demo:
    with gr.Row():
        # ä¸‹æ‹‰é€‰æ‹©æ¨¡å‹
        sovits_model_dropdown = gr.Dropdown(sovits_models, label="é€‰æ‹© SoVITS æ¨¡å‹")
        gpt_model_dropdown = gr.Dropdown(gpt_models, label="é€‰æ‹© GPT æ¨¡å‹")
    
    with gr.Row():
        # ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶
        ref_audio_input = gr.Audio(label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘", type="filepath")
        text_input = gr.Textbox(label="è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬", placeholder="è¯·è¾“å…¥æ–‡æœ¬")
    
    with gr.Row():
        # é¢å¤–å‚æ•°çš„è¾“å…¥æ¡†
        prompt_text_input = gr.Textbox(label="è¾“å…¥æç¤ºæ–‡æœ¬", value="ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„æ•°å­—äººåŠ©æ‰‹ï¼")
        prompt_language_input = gr.Dropdown(["ä¸­æ–‡", "è‹±æ–‡"], label="é€‰æ‹©æç¤ºè¯­è¨€", value="ä¸­æ–‡")
        how_to_cut_input = gr.Textbox(label="å¦‚ä½•åˆ‡å‰²æ–‡æœ¬", value="å‡‘å››å¥ä¸€åˆ‡")
        top_k_input = gr.Slider(minimum=1, maximum=50, label="Top-k", value=15)
        top_p_input = gr.Slider(minimum=0.0, maximum=1.0, label="Top-p", value=1.0)
        temperature_input = gr.Slider(minimum=0.0, maximum=2.0, label="temperature", value=1.0)
        ref_free_input = gr.Checkbox(label="å¼€å¯æ— å‚è€ƒæ–‡æœ¬æ¨¡å¼", value=False)
        speed_input = gr.Slider(minimum=0.5, maximum=2.0, label="è¯­é€Ÿ", value=1.0)
        if_freeze_input = gr.Checkbox(label="æ˜¯å¦ç›´æ¥å¯¹ä¸Šæ¬¡åˆæˆç»“æœè°ƒæ•´è¯­é€Ÿå’ŒéŸ³è‰²ã€‚é˜²æ­¢éšæœºæ€§ã€‚", value=False)
        sample_steps_input = gr.Slider(minimum=1, maximum=50, label="é‡‡æ ·æ­¥æ•°", value=8)

    with gr.Row():
        # ç”ŸæˆæŒ‰é’®
        generate_button = gr.Button("ç”Ÿæˆæ•°å­—äººè¯­éŸ³ä¸å”‡åŠ¨")
    
    with gr.Row():
        # è¾“å‡ºéŸ³é¢‘å’Œè§†é¢‘
        output_audio = gr.Audio(label="ç”Ÿæˆçš„éŸ³é¢‘")
        output_video = gr.Video(label="ç”Ÿæˆçš„è§†é¢‘")

    # è®¾ç½®ç”ŸæˆæŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶
    generate_button.click(
        gradio_interface,
        inputs=[
            ref_audio_input, 
            text_input, 
            sovits_model_dropdown, 
            gpt_model_dropdown,
            prompt_text_input, 
            prompt_language_input, 
            how_to_cut_input, 
            top_k_input, 
            top_p_input, 
            temperature_input, 
            ref_free_input, 
            speed_input, 
            if_freeze_input, 
            sample_steps_input
        ],
        outputs=[output_audio, output_video]
    )

# å¯åŠ¨ Web UI
demo.launch()
